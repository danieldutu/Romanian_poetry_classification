{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Romanian Poetry Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Exploratory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "My data has no header. By default pandas looks in the first row for the header. I have to tell pandas that my data has no header."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"train.csv\")\n",
    "test = pd.read_csv(\"test.csv\")\n",
    "\n",
    "\n",
    "#test = pd.read_csv(\"test.txt\", header = None)\n",
    "# sample_submission = pd.read_csv(\"/content/sample_submission.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Versuri</th>\n",
       "      <th>Autor</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gtGAdRcefKLbdSnHeADXAP</td>\n",
       "      <td>Frunzare se boltesc adânci\\npeste o-ntreagă po...</td>\n",
       "      <td>Lucian Blaga</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Vmy4wa4jueqTNxhMwJN8Z4</td>\n",
       "      <td>&lt;font size=\"-1\"&gt;Unui gazetar care cerea să fiu...</td>\n",
       "      <td>George Toparceanu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hp7rQvwXLjWcZhSYXDsAJU</td>\n",
       "      <td>Acum te odihneşte gustând eterna pace\\nÎn tain...</td>\n",
       "      <td>Vasile Alecsandri</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>FREBhCLk9Urz6YnBzuAe75</td>\n",
       "      <td>Şi mi-i ghioaga pintuită,\\nŞi mi-i inima-ncolţ...</td>\n",
       "      <td>Vasile Alecsandri</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>jXpfLZWB4UXxijS7KxJe9X</td>\n",
       "      <td>Hohot de smintit.\\nNici o urmă despre tine,\\n-...</td>\n",
       "      <td>George Bacovia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4264</th>\n",
       "      <td>DMCwENrHo94fpyWx6EWYoV</td>\n",
       "      <td>Lupta urlă, se-ncleştează\\nŞi barbarii toţi gr...</td>\n",
       "      <td>Vasile Alecsandri</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4265</th>\n",
       "      <td>TMwAUCWTYhFmQLFtmSsHNx</td>\n",
       "      <td>Şi fiindu-şi sie dragă cum nu-i este nime-n lu...</td>\n",
       "      <td>Mihai Eminescu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4266</th>\n",
       "      <td>jRBcajEAaetyxdQ8FxHwDK</td>\n",
       "      <td>\\nBătrânul Dan ascultă grăind doi vechi stejar...</td>\n",
       "      <td>Vasile Alecsandri</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4267</th>\n",
       "      <td>aiXNgaLRiKhbY4va5uK4gf</td>\n",
       "      <td>de la oameni la albine,\\nde la-nvingători la b...</td>\n",
       "      <td>Lucian Blaga</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4268</th>\n",
       "      <td>2eatwUabo6wUKWhAUL62WC</td>\n",
       "      <td>Să faci cucui!\\nSă nu-ţi arunc în ochi o stanţ...</td>\n",
       "      <td>George Toparceanu</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4269 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                          Id  \\\n",
       "0     gtGAdRcefKLbdSnHeADXAP   \n",
       "1     Vmy4wa4jueqTNxhMwJN8Z4   \n",
       "2     Hp7rQvwXLjWcZhSYXDsAJU   \n",
       "3     FREBhCLk9Urz6YnBzuAe75   \n",
       "4     jXpfLZWB4UXxijS7KxJe9X   \n",
       "...                      ...   \n",
       "4264  DMCwENrHo94fpyWx6EWYoV   \n",
       "4265  TMwAUCWTYhFmQLFtmSsHNx   \n",
       "4266  jRBcajEAaetyxdQ8FxHwDK   \n",
       "4267  aiXNgaLRiKhbY4va5uK4gf   \n",
       "4268  2eatwUabo6wUKWhAUL62WC   \n",
       "\n",
       "                                                Versuri              Autor  \n",
       "0     Frunzare se boltesc adânci\\npeste o-ntreagă po...       Lucian Blaga  \n",
       "1     <font size=\"-1\">Unui gazetar care cerea să fiu...  George Toparceanu  \n",
       "2     Acum te odihneşte gustând eterna pace\\nÎn tain...  Vasile Alecsandri  \n",
       "3     Şi mi-i ghioaga pintuită,\\nŞi mi-i inima-ncolţ...  Vasile Alecsandri  \n",
       "4     Hohot de smintit.\\nNici o urmă despre tine,\\n-...     George Bacovia  \n",
       "...                                                 ...                ...  \n",
       "4264  Lupta urlă, se-ncleştează\\nŞi barbarii toţi gr...  Vasile Alecsandri  \n",
       "4265  Şi fiindu-şi sie dragă cum nu-i este nime-n lu...     Mihai Eminescu  \n",
       "4266  \\nBătrânul Dan ascultă grăind doi vechi stejar...  Vasile Alecsandri  \n",
       "4267  de la oameni la albine,\\nde la-nvingători la b...       Lucian Blaga  \n",
       "4268  Să faci cucui!\\nSă nu-ţi arunc în ochi o stanţ...  George Toparceanu  \n",
       "\n",
       "[4269 rows x 3 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Derived text features, tweet-based (i.e. simple text features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_derived_features(df, text_source):\n",
    "    #token count\n",
    "    df['token_cnt'] = df[ text_source ].apply(lambda x: len(str(x).split(' ')) if ((x is not None) and (x!=np.nan)) else 0)\n",
    "\n",
    "    # character count\n",
    "    df['line_size'] = df[ text_source ].apply(lambda x: len(str(x)         )   )  \n",
    "\n",
    "    # non empty characters\n",
    "    df['empty_char_cnt'] = df[ text_source ].apply(lambda x: len([c for c in str(x) if c==' '])   )\n",
    "\n",
    "    # non empty characters\n",
    "    df['non_empty_char_cnt'] = df[ text_source ].apply(lambda x: len([c for c in str(x) if c!=' '])   )\n",
    "\n",
    "    #letters only\n",
    "    df['letter_cnt'] = df[ text_source ].apply(lambda x: len([c for c in str(x) if c.isalpha()])   )\n",
    "\n",
    "    #special characters only\n",
    "    df['special_char_cnt'] = df[ text_source ].apply(lambda x: len([c for c in str(x) if (not c.isalnum()) ])   )\n",
    "\n",
    "    #digits only\n",
    "    df['digits_cnt'] = df[ text_source ].apply(lambda x: len([c for c in str(x) if c.isnumeric()])   )\n",
    "\n",
    "    #relative counts\n",
    "    # non empty characters\n",
    "    df['empty_char_prct'] = df['empty_char_cnt'] /df['line_size']\n",
    "\n",
    "    # non empty characters\n",
    "    df['non_empty_char_prct'] = df['non_empty_char_cnt']/df['line_size']\n",
    "\n",
    "    #letters only\n",
    "    df['letter_prct'] = df['letter_cnt'] /df['line_size']\n",
    "\n",
    "    #special characters only\n",
    "    df['special_char_prct'] = df['special_char_cnt'] /df['line_size']\n",
    "\n",
    "    #digits only\n",
    "    df['digits_prct'] = df['digits_cnt']/df['line_size']\n",
    "\n",
    "\n",
    "    # catergories absolute count\n",
    "    df['is_alpha_cnt'] =df[ text_source ].apply(lambda x: len([t for t in str(x).split(' ') if t.isalpha() ] ))\n",
    "    df['is_mixed_alnum_cnt'] =df[ text_source ].apply(lambda x: len([t for t in str(x).split(' ') if t.isalnum() and\\\n",
    "                                                                     (not t.isalpha()) and (not t.isnumeric())] ))\n",
    "    df['is_numeric_cnt'] =df[ text_source ].apply(lambda x: len([t for t in str(x).split(' ') if t.isnumeric() ] ))\n",
    "    df['is_non_alnum_cnt'] =df[ text_source ].apply(lambda x: len( str(x).split(' ')  )-\\\n",
    "                                            len([t for t in str(x).split(' ') if t.isalnum() ] ))\n",
    "    # categories relative count\n",
    "    df['is_alpha_prct'] =df['is_alpha_cnt']/df['token_cnt']\n",
    "    df['is_numeric_prct'] =df['is_numeric_cnt']/df['token_cnt']\n",
    "    df['is_mixed_alnum_prct'] =df['is_mixed_alnum_cnt']/df['token_cnt']\n",
    "    df['is_non_alnum_prct'] =df['is_non_alnum_cnt']/df['token_cnt']\n",
    "\n",
    "    for c in ['is_alpha_prct','is_numeric_prct','is_mixed_alnum_prct','is_non_alnum_prct']:\n",
    "        df[c] = df[c].replace(np.inf, 2)\n",
    "        df[c] = df[c].replace(np.nan, -1)\n",
    "    # max and min token length by category; mean and std for lengths\n",
    "\n",
    "    # max\n",
    "    df['is_alpha_max_len'] =df[ text_source ].apply(lambda x: max([len(t) for t in str(x).split(' ') if t.isalpha() ] ) if\\\n",
    "                                                len([t for t in str(x).split(' ') if t.isalpha()])>0 else -1)\n",
    "    df['is_numeric_max_len'] =df[ text_source ].apply(lambda x: max([len(t) for t in str(x).split(' ') if t.isnumeric() ] )if\\\n",
    "                                                len([t for t in str(x).split(' ') if t.isnumeric()])>0 else -1)\n",
    "    df['is_mixed_alnum_max_len'] =df[ text_source ].apply(lambda x: max([len(t) for t in str(x).split(' ') if t.isalnum() and\\\n",
    "                                                                     (not t.isalpha()) and (not t.isnumeric())] )if\\\n",
    "                                                len([t for t in str(x).split(' ') if t.isalnum() and\\\n",
    "                                                                     (not t.isalpha()) and (not t.isnumeric())])>0 else -1)\n",
    "\n",
    "    df['is_non_alnum_max_len'] =df[ text_source ].apply(lambda x: max([len(t) for t in str(x).split(' ') if (not t.isalnum())] )if\\\n",
    "                                                len([t for t in str(x).split(' ') if (not t.isalnum())])>0 else -1)\n",
    "\n",
    "    # min\n",
    "    df['is_alpha_min_len'] =df[ text_source ].apply(lambda x: min([len(t) for t in str(x).split(' ') if t.isalpha() ] ) if\\\n",
    "                                                len([t for t in str(x).split(' ') if t.isalpha()])>0 else -1)\n",
    "    df['is_numeric_min_len'] =df[ text_source ].apply(lambda x: min([len(t) for t in str(x).split(' ') if t.isnumeric() ] )if\\\n",
    "                                                len([t for t in str(x).split(' ') if t.isnumeric()])>0 else -1)\n",
    "    df['is_mixed_alnum_min_len'] =df[ text_source ].apply(lambda x: min([len(t) for t in str(x).split(' ') if t.isalnum() and\\\n",
    "                                                                     (not t.isalpha()) and (not t.isnumeric())] )if\\\n",
    "                                                len([t for t in str(x).split(' ') if t.isalnum() and\\\n",
    "                                                                     (not t.isalpha()) and (not t.isnumeric())])>0 else -1)\n",
    "\n",
    "    df['is_non_alnum_min_len'] =df[ text_source ].apply(lambda x: min([len(t) for t in str(x).split(' ') if (not t.isalnum())] )if\\\n",
    "                                                len([t for t in str(x).split(' ') if (not t.isalnum())])>0 else -1)\n",
    "\n",
    "    # avg len\n",
    "    df['is_alpha_avg_len'] =df[ text_source ].apply(lambda x: np.mean([len(t) for t in str(x).split(' ') if t.isalpha() ] ) if\\\n",
    "                                                len([t for t in str(x).split(' ') if t.isalpha()])>0 else -1)\n",
    "    df['is_numeric_avg_len'] =df[ text_source ].apply(lambda x: np.mean([len(t) for t in str(x).split(' ') if t.isnumeric() ] )if\\\n",
    "                                                len([t for t in str(x).split(' ') if t.isnumeric()])>0 else -1)\n",
    "    df['is_mixed_alnum_avg_len'] =df[ text_source ].apply(lambda x: np.mean([len(t) for t in str(x).split(' ') if t.isalnum() and\\\n",
    "                                                                     (not t.isalpha()) and (not t.isnumeric())] )if\\\n",
    "                                                len([t for t in str(x).split(' ') if t.isalnum() and\\\n",
    "                                                                     (not t.isalpha()) and (not t.isnumeric())])>0 else -1)\n",
    "\n",
    "    df['is_non_alnum_avg_len'] =df[ text_source ].apply(lambda x: np.mean([len(t) for t in str(x).split(' ') if (not t.isalnum())] )if\\\n",
    "                                                len([t for t in str(x).split(' ') if (not t.isalnum())])>0 else -1)\n",
    "\n",
    "    # std for len\n",
    "    df['is_alpha_std_len'] =df[ text_source ].apply(lambda x: np.std([len(t) for t in str(x).split(' ') if t.isalpha() ] ) if\\\n",
    "                                                len([t for t in str(x).split(' ') if t.isalpha()])>0 else -1)\n",
    "    df['is_numeric_std_len'] =df[ text_source ].apply(lambda x: np.std([len(t) for t in str(x).split(' ') if t.isnumeric() ] )if\\\n",
    "                                                len([t for t in str(x).split(' ') if t.isnumeric()])>0 else -1)\n",
    "    df['is_mixed_alnum_std_len'] =df[ text_source ].apply(lambda x: np.std([len(t) for t in str(x).split(' ') if t.isalnum() and\\\n",
    "                                                                     (not t.isalpha()) and (not t.isnumeric())] )if\\\n",
    "                                                len([t for t in str(x).split(' ') if t.isalnum() and\\\n",
    "                                                                     (not t.isalpha()) and (not t.isnumeric())])>0 else -1)\n",
    "\n",
    "    df['is_non_alnum_std_len'] =df[ text_source ].apply(lambda x: np.std([len(t) for t in str(x).split(' ') if (not t.isalnum())] )if\\\n",
    "                                                len([t for t in str(x).split(' ') if (not t.isalnum())])>0 else -1)\n",
    "\n",
    "add_derived_features(train, 'Versuri')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Versuri</th>\n",
       "      <th>Autor</th>\n",
       "      <th>token_cnt</th>\n",
       "      <th>line_size</th>\n",
       "      <th>empty_char_cnt</th>\n",
       "      <th>non_empty_char_cnt</th>\n",
       "      <th>letter_cnt</th>\n",
       "      <th>special_char_cnt</th>\n",
       "      <th>digits_cnt</th>\n",
       "      <th>...</th>\n",
       "      <th>is_mixed_alnum_min_len</th>\n",
       "      <th>is_non_alnum_min_len</th>\n",
       "      <th>is_alpha_avg_len</th>\n",
       "      <th>is_numeric_avg_len</th>\n",
       "      <th>is_mixed_alnum_avg_len</th>\n",
       "      <th>is_non_alnum_avg_len</th>\n",
       "      <th>is_alpha_std_len</th>\n",
       "      <th>is_numeric_std_len</th>\n",
       "      <th>is_mixed_alnum_std_len</th>\n",
       "      <th>is_non_alnum_std_len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gtGAdRcefKLbdSnHeADXAP</td>\n",
       "      <td>Frunzare se boltesc adânci\\npeste o-ntreagă po...</td>\n",
       "      <td>Lucian Blaga</td>\n",
       "      <td>18</td>\n",
       "      <td>128</td>\n",
       "      <td>17</td>\n",
       "      <td>111</td>\n",
       "      <td>105</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>-1</td>\n",
       "      <td>9</td>\n",
       "      <td>4.642857</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1</td>\n",
       "      <td>11.500000</td>\n",
       "      <td>1.985920</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1</td>\n",
       "      <td>1.802776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Vmy4wa4jueqTNxhMwJN8Z4</td>\n",
       "      <td>&lt;font size=\"-1\"&gt;Unui gazetar care cerea să fiu...</td>\n",
       "      <td>George Toparceanu</td>\n",
       "      <td>21</td>\n",
       "      <td>155</td>\n",
       "      <td>20</td>\n",
       "      <td>135</td>\n",
       "      <td>114</td>\n",
       "      <td>40</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>-1</td>\n",
       "      <td>5</td>\n",
       "      <td>3.615385</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>1.982169</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1</td>\n",
       "      <td>5.545268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hp7rQvwXLjWcZhSYXDsAJU</td>\n",
       "      <td>Acum te odihneşte gustând eterna pace\\nÎn tain...</td>\n",
       "      <td>Vasile Alecsandri</td>\n",
       "      <td>25</td>\n",
       "      <td>167</td>\n",
       "      <td>24</td>\n",
       "      <td>143</td>\n",
       "      <td>131</td>\n",
       "      <td>36</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>-1</td>\n",
       "      <td>3</td>\n",
       "      <td>4.176471</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>2.617482</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1</td>\n",
       "      <td>3.535534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>FREBhCLk9Urz6YnBzuAe75</td>\n",
       "      <td>Şi mi-i ghioaga pintuită,\\nŞi mi-i inima-ncolţ...</td>\n",
       "      <td>Vasile Alecsandri</td>\n",
       "      <td>12</td>\n",
       "      <td>102</td>\n",
       "      <td>11</td>\n",
       "      <td>91</td>\n",
       "      <td>78</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>-1</td>\n",
       "      <td>4</td>\n",
       "      <td>3.833333</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1</td>\n",
       "      <td>11.333333</td>\n",
       "      <td>1.950783</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1</td>\n",
       "      <td>7.086764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>jXpfLZWB4UXxijS7KxJe9X</td>\n",
       "      <td>Hohot de smintit.\\nNici o urmă despre tine,\\n-...</td>\n",
       "      <td>George Bacovia</td>\n",
       "      <td>12</td>\n",
       "      <td>86</td>\n",
       "      <td>11</td>\n",
       "      <td>75</td>\n",
       "      <td>60</td>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>-1</td>\n",
       "      <td>5</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1</td>\n",
       "      <td>9.400000</td>\n",
       "      <td>2.329929</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1</td>\n",
       "      <td>2.727636</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 39 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Id                                            Versuri  \\\n",
       "0  gtGAdRcefKLbdSnHeADXAP  Frunzare se boltesc adânci\\npeste o-ntreagă po...   \n",
       "1  Vmy4wa4jueqTNxhMwJN8Z4  <font size=\"-1\">Unui gazetar care cerea să fiu...   \n",
       "2  Hp7rQvwXLjWcZhSYXDsAJU  Acum te odihneşte gustând eterna pace\\nÎn tain...   \n",
       "3  FREBhCLk9Urz6YnBzuAe75  Şi mi-i ghioaga pintuită,\\nŞi mi-i inima-ncolţ...   \n",
       "4  jXpfLZWB4UXxijS7KxJe9X  Hohot de smintit.\\nNici o urmă despre tine,\\n-...   \n",
       "\n",
       "               Autor  token_cnt  line_size  empty_char_cnt  \\\n",
       "0       Lucian Blaga         18        128              17   \n",
       "1  George Toparceanu         21        155              20   \n",
       "2  Vasile Alecsandri         25        167              24   \n",
       "3  Vasile Alecsandri         12        102              11   \n",
       "4     George Bacovia         12         86              11   \n",
       "\n",
       "   non_empty_char_cnt  letter_cnt  special_char_cnt  digits_cnt  ...  \\\n",
       "0                 111         105                23           0  ...   \n",
       "1                 135         114                40           1  ...   \n",
       "2                 143         131                36           0  ...   \n",
       "3                  91          78                24           0  ...   \n",
       "4                  75          60                26           0  ...   \n",
       "\n",
       "   is_mixed_alnum_min_len  is_non_alnum_min_len  is_alpha_avg_len  \\\n",
       "0                      -1                     9          4.642857   \n",
       "1                      -1                     5          3.615385   \n",
       "2                      -1                     3          4.176471   \n",
       "3                      -1                     4          3.833333   \n",
       "4                      -1                     5          4.000000   \n",
       "\n",
       "   is_numeric_avg_len  is_mixed_alnum_avg_len  is_non_alnum_avg_len  \\\n",
       "0                -1.0                      -1             11.500000   \n",
       "1                -1.0                      -1             11.000000   \n",
       "2                -1.0                      -1              9.000000   \n",
       "3                -1.0                      -1             11.333333   \n",
       "4                -1.0                      -1              9.400000   \n",
       "\n",
       "   is_alpha_std_len  is_numeric_std_len  is_mixed_alnum_std_len  \\\n",
       "0          1.985920                -1.0                      -1   \n",
       "1          1.982169                -1.0                      -1   \n",
       "2          2.617482                -1.0                      -1   \n",
       "3          1.950783                -1.0                      -1   \n",
       "4          2.329929                -1.0                      -1   \n",
       "\n",
       "   is_non_alnum_std_len  \n",
       "0              1.802776  \n",
       "1              5.545268  \n",
       "2              3.535534  \n",
       "3              7.086764  \n",
       "4              2.727636  \n",
       "\n",
       "[5 rows x 39 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4269, 39)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Versuri</th>\n",
       "      <th>Autor</th>\n",
       "      <th>token_cnt</th>\n",
       "      <th>line_size</th>\n",
       "      <th>empty_char_cnt</th>\n",
       "      <th>non_empty_char_cnt</th>\n",
       "      <th>letter_cnt</th>\n",
       "      <th>special_char_cnt</th>\n",
       "      <th>digits_cnt</th>\n",
       "      <th>...</th>\n",
       "      <th>is_mixed_alnum_min_len</th>\n",
       "      <th>is_non_alnum_min_len</th>\n",
       "      <th>is_alpha_avg_len</th>\n",
       "      <th>is_numeric_avg_len</th>\n",
       "      <th>is_mixed_alnum_avg_len</th>\n",
       "      <th>is_non_alnum_avg_len</th>\n",
       "      <th>is_alpha_std_len</th>\n",
       "      <th>is_numeric_std_len</th>\n",
       "      <th>is_mixed_alnum_std_len</th>\n",
       "      <th>is_non_alnum_std_len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gtGAdRcefKLbdSnHeADXAP</td>\n",
       "      <td>Frunzare se boltesc adânci\\npeste o-ntreagă po...</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>128</td>\n",
       "      <td>17</td>\n",
       "      <td>111</td>\n",
       "      <td>105</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>-1</td>\n",
       "      <td>9</td>\n",
       "      <td>4.642857</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1</td>\n",
       "      <td>11.500000</td>\n",
       "      <td>1.985920</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1</td>\n",
       "      <td>1.802776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Vmy4wa4jueqTNxhMwJN8Z4</td>\n",
       "      <td>&lt;font size=\"-1\"&gt;Unui gazetar care cerea să fiu...</td>\n",
       "      <td>1</td>\n",
       "      <td>21</td>\n",
       "      <td>155</td>\n",
       "      <td>20</td>\n",
       "      <td>135</td>\n",
       "      <td>114</td>\n",
       "      <td>40</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>-1</td>\n",
       "      <td>5</td>\n",
       "      <td>3.615385</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>1.982169</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1</td>\n",
       "      <td>5.545268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hp7rQvwXLjWcZhSYXDsAJU</td>\n",
       "      <td>Acum te odihneşte gustând eterna pace\\nÎn tain...</td>\n",
       "      <td>2</td>\n",
       "      <td>25</td>\n",
       "      <td>167</td>\n",
       "      <td>24</td>\n",
       "      <td>143</td>\n",
       "      <td>131</td>\n",
       "      <td>36</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>-1</td>\n",
       "      <td>3</td>\n",
       "      <td>4.176471</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>2.617482</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1</td>\n",
       "      <td>3.535534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>FREBhCLk9Urz6YnBzuAe75</td>\n",
       "      <td>Şi mi-i ghioaga pintuită,\\nŞi mi-i inima-ncolţ...</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>102</td>\n",
       "      <td>11</td>\n",
       "      <td>91</td>\n",
       "      <td>78</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>-1</td>\n",
       "      <td>4</td>\n",
       "      <td>3.833333</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1</td>\n",
       "      <td>11.333333</td>\n",
       "      <td>1.950783</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1</td>\n",
       "      <td>7.086764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>jXpfLZWB4UXxijS7KxJe9X</td>\n",
       "      <td>Hohot de smintit.\\nNici o urmă despre tine,\\n-...</td>\n",
       "      <td>3</td>\n",
       "      <td>12</td>\n",
       "      <td>86</td>\n",
       "      <td>11</td>\n",
       "      <td>75</td>\n",
       "      <td>60</td>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>-1</td>\n",
       "      <td>5</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1</td>\n",
       "      <td>9.400000</td>\n",
       "      <td>2.329929</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1</td>\n",
       "      <td>2.727636</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 39 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Id                                            Versuri  \\\n",
       "0  gtGAdRcefKLbdSnHeADXAP  Frunzare se boltesc adânci\\npeste o-ntreagă po...   \n",
       "1  Vmy4wa4jueqTNxhMwJN8Z4  <font size=\"-1\">Unui gazetar care cerea să fiu...   \n",
       "2  Hp7rQvwXLjWcZhSYXDsAJU  Acum te odihneşte gustând eterna pace\\nÎn tain...   \n",
       "3  FREBhCLk9Urz6YnBzuAe75  Şi mi-i ghioaga pintuită,\\nŞi mi-i inima-ncolţ...   \n",
       "4  jXpfLZWB4UXxijS7KxJe9X  Hohot de smintit.\\nNici o urmă despre tine,\\n-...   \n",
       "\n",
       "   Autor  token_cnt  line_size  empty_char_cnt  non_empty_char_cnt  \\\n",
       "0      0         18        128              17                 111   \n",
       "1      1         21        155              20                 135   \n",
       "2      2         25        167              24                 143   \n",
       "3      2         12        102              11                  91   \n",
       "4      3         12         86              11                  75   \n",
       "\n",
       "   letter_cnt  special_char_cnt  digits_cnt  ...  is_mixed_alnum_min_len  \\\n",
       "0         105                23           0  ...                      -1   \n",
       "1         114                40           1  ...                      -1   \n",
       "2         131                36           0  ...                      -1   \n",
       "3          78                24           0  ...                      -1   \n",
       "4          60                26           0  ...                      -1   \n",
       "\n",
       "   is_non_alnum_min_len  is_alpha_avg_len  is_numeric_avg_len  \\\n",
       "0                     9          4.642857                -1.0   \n",
       "1                     5          3.615385                -1.0   \n",
       "2                     3          4.176471                -1.0   \n",
       "3                     4          3.833333                -1.0   \n",
       "4                     5          4.000000                -1.0   \n",
       "\n",
       "   is_mixed_alnum_avg_len  is_non_alnum_avg_len  is_alpha_std_len  \\\n",
       "0                      -1             11.500000          1.985920   \n",
       "1                      -1             11.000000          1.982169   \n",
       "2                      -1              9.000000          2.617482   \n",
       "3                      -1             11.333333          1.950783   \n",
       "4                      -1              9.400000          2.329929   \n",
       "\n",
       "   is_numeric_std_len  is_mixed_alnum_std_len  is_non_alnum_std_len  \n",
       "0                -1.0                      -1              1.802776  \n",
       "1                -1.0                      -1              5.545268  \n",
       "2                -1.0                      -1              3.535534  \n",
       "3                -1.0                      -1              7.086764  \n",
       "4                -1.0                      -1              2.727636  \n",
       "\n",
       "[5 rows x 39 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = train['Autor'].unique().tolist()\n",
    "train['Autor'] = train['Autor'].apply(lambda x:labels.index(x))\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_cols = [c for c in train.columns if c not in ['Id','Autor']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Modelling "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split multiple times in train and test\n",
    "For now I split once, setting the random_state so that if I want to work later everything is traceable.\n",
    "\n",
    "Once the model is found, I repeat this split and the training say 100 times, with random_state eliminated so that the splits are independent and not repeatable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39 37 37\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(train[train_cols], train[['Autor']], test_size=0.2, \n",
    "                                                    random_state=7) # this will have to stay loose if we want to properly\n",
    "                                                                     # evaluate the model performance and split several time\n",
    "print(train.shape[1], X_train.shape[1],X_test.shape[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Part of feature engineering I need to add text features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Alexa\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# !pip install nltk\n",
    "import nltk\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "german_stop_words = stopwords.words('romanian')\n",
    "import nltk\n",
    "\n",
    "\n",
    "#from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "vectorizer = TfidfVectorizer(max_features =5000, # max words for 'vocabulary' - to run this eg. \n",
    "                             max_df = 0.3, # max frequency for words in vocabulary \n",
    "                             min_df = 0.001, # min frequency for words in vocabulary\n",
    "                             token_pattern  = '[a-zA-Z]{3,20}', #just look for words at least 3 char long and no more than 20\n",
    "                             smooth_idf = True, \n",
    "                             #binary = True,\n",
    "                             stop_words = german_stop_words # german stop words loaded - not sure how efficient this is but worth trying\n",
    "                                  )\n",
    "\n",
    "# applies the fit_transform on the training set and the transform on the test set\n",
    "def add_text_features(df_train,df_test):\n",
    "\n",
    "    X_train_tfidf = vectorizer.fit_transform(df_train['Versuri'])\n",
    "     \n",
    "    print(\"Train Vectorized Shape: \", X_train_tfidf.shape)\n",
    "\n",
    "    X_test_tfidf = vectorizer.transform(df_test['Versuri'])\n",
    "    print(\"Test Vectorized Shape: \", X_test_tfidf.shape)\n",
    "    \n",
    "    #### Adding sparse data series from vectorization as columns in dataframe\n",
    "    for i, col in enumerate(vectorizer.get_feature_names()):\n",
    "        \n",
    "        #x = pd.Series(pd.array.Sparse(X_train_tfidf[:, i].toarray().ravel()))\n",
    "        if col in df_train.columns:\n",
    "            df_train.drop(columns = [col],inplace = True)\n",
    "        if col in df_test.columns:\n",
    "            df_test.drop(columns = [col],inplace = True)\n",
    "        df_train.loc[:,col] = X_train_tfidf[:, i].toarray()\n",
    "        df_test[col] = X_test_tfidf[:, i].toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the final thing to be used - but first cross validation; inside the cross validation need to add features to splits\n",
    "the same need to be done when training on this below...\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X_train[[c for c in X_train.columns if c !='Versuri']].to_numpy()\n",
    "y= y_train.to_numpy()\n",
    "\n",
    "X_eval = X_test[[c for c in X_test.columns if c !='Versuri']].to_numpy()\n",
    "y_eval = y_test.to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fitting Random Forest Regression to the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Overfitting is controlled by max_samples.\n",
    "\n",
    "I can play with the word freq and max samples to tune the algorithm. the estimators might not play a big role, although when max_samples is small, than up to some point we want to add estimators in order to explore the entire data set with as many disjoint opinions (from estimators for which the training set is not overlapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "regressor = RandomForestClassifier(n_estimators =10000, \n",
    "                                  criterion = 'gini',\n",
    "                                  max_samples =0.1,\n",
    "                                  n_jobs = -1,\n",
    "                                  random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Alexa\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\feature_extraction\\text.py:383: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ace', 'aceast', 'aib', 'ave', 'dac', 'dou', 'dup', 'ina', 'ine', 'lea', 'mul', 'noastr', 'oric', 'printr', 'rei', 'ror', 'rui', 'sta', 'stea', 'sunte', 'tia', 'toat', 'totu', 'tre', 'tri', 'tva', 'voastr', 'vou'] not in stop_words.\n",
      "  warnings.warn('Your stop_words may be inconsistent with '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Vectorized Shape:  (3415, 1994)\n",
      "Test Vectorized Shape:  (854, 1994)\n"
     ]
    }
   ],
   "source": [
    "import copy\n",
    "\n",
    "# make a hard copy of the X_train to avoid messing up with the cross-validation if a cross-validation was used\n",
    "X_train_orig = copy.deepcopy(X_train)\n",
    "X_test_orig = copy.deepcopy(X_test)\n",
    "\n",
    "# add text features (vectorization) - that is prepare the train and test features\n",
    "add_text_features(X_train_orig,X_test_orig)\n",
    "\n",
    "# convert to numpy arrays\n",
    "X = X_train_orig[[c for c in X_train_orig.columns if c !='Versuri']].to_numpy()\n",
    "y= y_train.to_numpy()\n",
    "\n",
    "X_eval = X_test_orig[[c for c in X_test_orig.columns if c !='Versuri']].to_numpy()\n",
    "y_eval = y_test.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<timed exec>:3: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 39.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# set up the regressor and fit on big training set\n",
    "regressor.max_features =int(round(X.shape[1]*0.33,0))\n",
    "regressor.fit(X,y)\n",
    "\n",
    "# predict on train and test\n",
    "# y_hat_fit = regressor.predict(X)\n",
    "y_hat_eval = regressor.predict(X_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         3\n",
      "           1       0.01      0.20      0.02         5\n",
      "           2       0.38      0.44      0.40       124\n",
      "           3       0.00      0.00      0.00         1\n",
      "           4       0.77      0.40      0.53       463\n",
      "           5       0.60      0.51      0.55       219\n",
      "           6       0.13      0.28      0.18        39\n",
      "\n",
      "    accuracy                           0.43       854\n",
      "   macro avg       0.27      0.26      0.24       854\n",
      "weighted avg       0.63      0.43      0.49       854\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "print(metrics.classification_report(y_hat_eval, y_eval))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Submission part "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since there is a submission sample, I will try to respect the format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Versuri</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>asPpWqsLJfmiX8BiEf3gmm</td>\n",
       "      <td>Sus, pe dealuri, Toamna pune\\nMirişti galbene-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>oJWxeVPj4QVvqeaqYcuQJK</td>\n",
       "      <td>Te sărut şi eu şi Luna,\\nIzvoraşule.\\nCă eşti ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>VfrePwDMD4cCausKZ5X5cf</td>\n",
       "      <td>Ah! viaţa pentru mine,\\nScump înger! fără tine...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>857QzB65ijZQGaoSjEaEnn</td>\n",
       "      <td>Cum aş zidi un val,\\nA doua zi iar,\\nA treia z...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>cZSmeqnMgw56oadzt3EfAz</td>\n",
       "      <td>Cu creionul dus la gură,\\nNecăjit fără măsură,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Id                                            Versuri\n",
       "0  asPpWqsLJfmiX8BiEf3gmm  Sus, pe dealuri, Toamna pune\\nMirişti galbene-...\n",
       "1  oJWxeVPj4QVvqeaqYcuQJK  Te sărut şi eu şi Luna,\\nIzvoraşule.\\nCă eşti ...\n",
       "2  VfrePwDMD4cCausKZ5X5cf  Ah! viaţa pentru mine,\\nScump înger! fără tine...\n",
       "3  857QzB65ijZQGaoSjEaEnn  Cum aş zidi un val,\\nA doua zi iar,\\nA treia z...\n",
       "4  cZSmeqnMgw56oadzt3EfAz  Cu creionul dus la gură,\\nNecăjit fără măsură,..."
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "ids = test.Id\n",
    "test = test[['Versuri']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also need to apply the same feature engineering to the real unseen data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_derived_features(test, 'Versuri')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Vectorized Shape:  (1068, 1994)\n"
     ]
    }
   ],
   "source": [
    "X_test_tfidf_real = vectorizer.transform(test['Versuri'])\n",
    "print(\"Test Vectorized Shape: \", X_test_tfidf_real.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, col in enumerate(vectorizer.get_feature_names()):\n",
    "        \n",
    "        if col in test.columns:\n",
    "            test.drop(columns = [col],inplace = True)\n",
    "        test[col] = X_test_tfidf_real[:, i].toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Versuri</th>\n",
       "      <th>token_cnt</th>\n",
       "      <th>line_size</th>\n",
       "      <th>empty_char_cnt</th>\n",
       "      <th>non_empty_char_cnt</th>\n",
       "      <th>letter_cnt</th>\n",
       "      <th>special_char_cnt</th>\n",
       "      <th>digits_cnt</th>\n",
       "      <th>empty_char_prct</th>\n",
       "      <th>non_empty_char_prct</th>\n",
       "      <th>...</th>\n",
       "      <th>zmeu</th>\n",
       "      <th>zne</th>\n",
       "      <th>znesc</th>\n",
       "      <th>zori</th>\n",
       "      <th>zorii</th>\n",
       "      <th>zugr</th>\n",
       "      <th>zui</th>\n",
       "      <th>zut</th>\n",
       "      <th>zute</th>\n",
       "      <th>zvon</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sus, pe dealuri, Toamna pune\\nMirişti galbene-...</td>\n",
       "      <td>13</td>\n",
       "      <td>98</td>\n",
       "      <td>12</td>\n",
       "      <td>86</td>\n",
       "      <td>78</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>0.122449</td>\n",
       "      <td>0.877551</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Te sărut şi eu şi Luna,\\nIzvoraşule.\\nCă eşti ...</td>\n",
       "      <td>11</td>\n",
       "      <td>75</td>\n",
       "      <td>10</td>\n",
       "      <td>65</td>\n",
       "      <td>58</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ah! viaţa pentru mine,\\nScump înger! fără tine...</td>\n",
       "      <td>15</td>\n",
       "      <td>86</td>\n",
       "      <td>14</td>\n",
       "      <td>72</td>\n",
       "      <td>64</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>0.162791</td>\n",
       "      <td>0.837209</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Cum aş zidi un val,\\nA doua zi iar,\\nA treia z...</td>\n",
       "      <td>14</td>\n",
       "      <td>66</td>\n",
       "      <td>13</td>\n",
       "      <td>53</td>\n",
       "      <td>46</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>0.196970</td>\n",
       "      <td>0.803030</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Cu creionul dus la gură,\\nNecăjit fără măsură,...</td>\n",
       "      <td>15</td>\n",
       "      <td>92</td>\n",
       "      <td>14</td>\n",
       "      <td>78</td>\n",
       "      <td>72</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>0.152174</td>\n",
       "      <td>0.847826</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 2031 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Versuri  token_cnt  line_size  \\\n",
       "0  Sus, pe dealuri, Toamna pune\\nMirişti galbene-...         13         98   \n",
       "1  Te sărut şi eu şi Luna,\\nIzvoraşule.\\nCă eşti ...         11         75   \n",
       "2  Ah! viaţa pentru mine,\\nScump înger! fără tine...         15         86   \n",
       "3  Cum aş zidi un val,\\nA doua zi iar,\\nA treia z...         14         66   \n",
       "4  Cu creionul dus la gură,\\nNecăjit fără măsură,...         15         92   \n",
       "\n",
       "   empty_char_cnt  non_empty_char_cnt  letter_cnt  special_char_cnt  \\\n",
       "0              12                  86          78                20   \n",
       "1              10                  65          58                17   \n",
       "2              14                  72          64                22   \n",
       "3              13                  53          46                20   \n",
       "4              14                  78          72                20   \n",
       "\n",
       "   digits_cnt  empty_char_prct  non_empty_char_prct  ...  zmeu  zne  znesc  \\\n",
       "0           0         0.122449             0.877551  ...   0.0  0.0    0.0   \n",
       "1           0         0.133333             0.866667  ...   0.0  0.0    0.0   \n",
       "2           0         0.162791             0.837209  ...   0.0  0.0    0.0   \n",
       "3           0         0.196970             0.803030  ...   0.0  0.0    0.0   \n",
       "4           0         0.152174             0.847826  ...   0.0  0.0    0.0   \n",
       "\n",
       "   zori  zorii  zugr  zui  zut  zute  zvon  \n",
       "0   0.0    0.0   0.0  0.0  0.0   0.0   0.0  \n",
       "1   0.0    0.0   0.0  0.0  0.0   0.0   0.0  \n",
       "2   0.0    0.0   0.0  0.0  0.0   0.0   0.0  \n",
       "3   0.0    0.0   0.0  0.0  0.0   0.0   0.0  \n",
       "4   0.0    0.0   0.0  0.0  0.0   0.0   0.0  \n",
       "\n",
       "[5 rows x 2031 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_eval_real' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-24-09d70891ff26>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mX_eval_real\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'X_eval_real' is not defined"
     ]
    }
   ],
   "source": [
    "X_eval_real.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_eval_real = test[[c for c in test.columns if c !='Versuri']].to_numpy()\n",
    "X_eval_real.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_tfidf_real.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat_eval_real = regressor.predict(X_eval_real)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat_eval_real"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission['Autor'] = y_hat_eval_real"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission['Autor'] = submission['Autor'].apply(lambda x: labels[x])\n",
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission['Id'] = ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv('submission.csv', index=False)\n",
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
